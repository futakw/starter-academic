---
title: "Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships"

# Authors
authors:
- admin
- Antonio Tejero-de-Pablos
- Isao Echizen

date: "2025-11-01T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: "2025-11-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: "WACV 2026"
publication_short: "WACV 2026"

abstract: "Vision-Language Models (VLMs) are increasingly adopted in practical applications, but remain vulnerable to adversarial perturbations. Existing adversarial fine-tuning methods often rely on one-to-one image-text supervision and may overfit to narrow language cues. This work studies multimodal defense with one-to-many relationships between images and textual descriptions, improving robustness under stronger attack settings while retaining clean performance."
highlights:
- Targets robust defense for VLMs under multimodal adversarial attacks.
- Leverages one-to-many image-text relationships during adversarial training.
- Improves robustness while preserving clean-task performance.

tags: ["recent"]

# Display this page in the Featured widget?
featured: false

url_pdf: 'https://arxiv.org/abs/2405.18770'
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
image:
  caption: ''
  focal_point: ""
  preview_only: false
---
